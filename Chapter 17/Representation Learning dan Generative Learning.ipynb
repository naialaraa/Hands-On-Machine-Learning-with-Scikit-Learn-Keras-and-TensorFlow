{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 17: Representation Learning dan Generative Learning\n",
        "## Autoencoders & Generative Adversarial Networks (GANs)\n",
        "\n",
        "Bab ini membahas teknik pembelajaran tanpa pengawasan (*unsupervised*) untuk mempelajari representasi data yang padat. Kita akan mempelajari bagaimana **Autoencoders** mengompresi informasi dan bagaimana **GANs** menghasilkan data baru melalui kompetisi antar jaringan.\n",
        "\n",
        "### Fokus Pembelajaran:\n",
        "1. **Prinsip Dasar Autoencoder**: Efek *bottleneck*.\n",
        "2. **Stacked & Convolutional Autoencoders**: Menangani data gambar secara hierarkis.\n",
        "3. **Denoising & Sparse Autoencoders**: Teknik regularisasi representasi.\n",
        "4. **Variational Autoencoders (VAE)**: Pintu masuk ke dunia model generatif.\n",
        "5. **Generative Adversarial Networks (GAN)**: Dinamika Generator vs Discriminator.\n",
        "6. **Deep Convolutional GAN (DCGAN)**: Standar untuk pembuatan gambar sintetis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Undercomplete Autoencoders\n",
        "\n",
        "Autoencoder yang paling sederhana adalah yang memiliki lapisan tersembunyi dengan dimensi lebih kecil dari input. Ini memaksa jaringan untuk mempelajari fitur yang paling penting (mirip dengan PCA jika lapisannya linear)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Membuat data sintetis 3D yang sebenarnya berada pada bidang 2D\n",
        "def generate_3d_data(m, w1=0.1, w2=0.3, noise=0.1):\n",
        "    angles = np.random.rand(m) * 3 * np.pi / 2 - 0.5\n",
        "    data = np.empty((m, 3))\n",
        "    data[:, 0] = np.cos(angles) + np.sin(angles)/2 + noise * np.random.randn(m) / 2\n",
        "    data[:, 1] = np.sin(angles) * 0.7 + noise * np.random.randn(m) / 2\n",
        "    data[:, 2] = data[:, 0] * w1 + data[:, 1] * w2 + noise * np.random.randn(m)\n",
        "    return data\n",
        "\n",
        "X_train = generate_3d_data(100)\n",
        "X_train = X_train - X_train.mean(axis=0)\n",
        "\n",
        "# Membangun Autoencoder Linear (2 neuron di bottleneck)\n",
        "encoder = keras.models.Sequential([keras.layers.Dense(2, input_shape=[3])])\n",
        "decoder = keras.models.Sequential([keras.layers.Dense(3, input_shape=[2])])\n",
        "autoencoder = keras.models.Sequential([encoder, decoder])\n",
        "\n",
        "autoencoder.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=0.1))\n",
        "history = autoencoder.fit(X_train, X_train, epochs=20, verbose=0)\n",
        "\n",
        "print(\"Pelatihan Autoencoder Linear selesai. Loss akhir:\", history.history['loss'][-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Stacked Autoencoders\n",
        "\n",
        "Stacked Autoencoder memiliki beberapa lapisan tersembunyi. Keuntungannya adalah kemampuan untuk mempelajari fitur yang lebih kompleks. Namun, jika terlalu banyak kapasitas, autoencoder bisa saja hanya \"menyalin\" tanpa belajar (overfitting)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Memuat dataset Fashion MNIST\n",
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full.astype(np.float32) / 255\n",
        "X_test = X_test.astype(np.float32) / 255\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "\n",
        "def build_stacked_autoencoder():\n",
        "    # Encoder: 784 -> 100 -> 30\n",
        "    encoder = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dense(100, activation=\"selu\"),\n",
        "        keras.layers.Dense(30, activation=\"selu\"),\n",
        "    ])\n",
        "    # Decoder: 30 -> 100 -> 784\n",
        "    decoder = keras.models.Sequential([\n",
        "        keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
        "        keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "        keras.layers.Reshape([28, 28])\n",
        "    ])\n",
        "    return keras.models.Sequential([encoder, decoder])\n",
        "\n",
        "stacked_ae = build_stacked_autoencoder()\n",
        "stacked_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(learning_rate=1.5))\n",
        "print(\"Arsitektur Stacked Autoencoder siap.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Convolutional Autoencoders\n",
        "\n",
        "Sama seperti CNN untuk klasifikasi, Convolutional Autoencoder menggunakan lapisan `Conv2D` untuk encoder dan `Conv2DTranspose` untuk decoder (untuk menaikkan resolusi gambar kembali)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conv_encoder = keras.models.Sequential([\n",
        "    keras.layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n",
        "    keras.layers.Conv2D(16, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(pool_size=2),\n",
        "    keras.layers.Conv2D(32, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(pool_size=2),\n",
        "    keras.layers.Conv2D(64, kernel_size=3, padding=\"SAME\", activation=\"selu\"),\n",
        "    keras.layers.MaxPool2D(pool_size=2)\n",
        "])\n",
        "\n",
        "conv_decoder = keras.models.Sequential([\n",
        "    keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding=\"VALID\", activation=\"selu\", input_shape=[3, 3, 64]),\n",
        "    keras.layers.Conv2DTranspose(16, kernel_size=3, strides=2, padding=\"SAME\", activation=\"selu\"),\n",
        "    keras.layers.Conv2DTranspose(1, kernel_size=3, strides=2, padding=\"SAME\", activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "\n",
        "conv_ae = keras.models.Sequential([conv_encoder, conv_decoder])\n",
        "conv_ae.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Variational Autoencoders (VAE)\n",
        "\n",
        "VAE adalah model generatif. Alih-alih memetakan input ke titik tunggal di *latent space*, VAE memetakan input ke distribusi probabilitas. Ini memungkinkan kita menghasilkan gambar baru dengan melakukan sampling dari distribusi tersebut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Sampling(keras.layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        mean, log_var = inputs\n",
        "        return tf.random.normal(tf.shape(log_var)) * tf.exp(log_var / 2) + mean\n",
        "\n",
        "# Encoder VAE\n",
        "latent_dim = 2\n",
        "inputs = keras.layers.Input(shape=[28, 28])\n",
        "z = keras.layers.Flatten()(inputs)\n",
        "z = keras.layers.Dense(150, activation=\"selu\")(z)\n",
        "z = keras.layers.Dense(100, activation=\"selu\")(z)\n",
        "codings_mean = keras.layers.Dense(latent_dim)(z)\n",
        "codings_log_var = keras.layers.Dense(latent_dim)(z)\n",
        "codings = Sampling()([codings_mean, codings_log_var])\n",
        "vae_encoder = keras.models.Model(inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])\n",
        "\n",
        "# Decoder VAE\n",
        "decoder_inputs = keras.layers.Input(shape=[latent_dim])\n",
        "x = keras.layers.Dense(100, activation=\"selu\")(decoder_inputs)\n",
        "x = keras.layers.Dense(150, activation=\"selu\")(x)\n",
        "x = keras.layers.Dense(28 * 28, activation=\"sigmoid\")(x)\n",
        "outputs = keras.layers.Reshape([28, 28])(x)\n",
        "vae_decoder = keras.models.Model(inputs=[decoder_inputs], outputs=[outputs])\n",
        "\n",
        "print(\"Variational Autoencoder berhasil didefinisikan.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Generative Adversarial Networks (GANs)\n",
        "\n",
        "GAN melatih dua model secara bersamaan:\n",
        "- **Generator**: Membuat data palsu dari kebisingan acak (*random noise*).\n",
        "- **Discriminator**: Menentukan apakah data itu asli (dari dataset) atau palsu (dari generator).\n",
        "\n",
        "Proses ini adalah kompetisi terus-menerus hingga generator menghasilkan data yang tidak bisa dibedakan lagi oleh discriminator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generator GAN Sederhana\n",
        "codings_size = 30\n",
        "generator = keras.models.Sequential([\n",
        "    keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n",
        "    keras.layers.Dense(150, activation=\"selu\"),\n",
        "    keras.layers.Dense(28 * 28, activation=\"sigmoid\"),\n",
        "    keras.layers.Reshape([28, 28])\n",
        "])\n",
        "\n",
        "# Discriminator GAN Sederhana\n",
        "discriminator = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28]),\n",
        "    keras.layers.Dense(150, activation=\"selu\"),\n",
        "    keras.layers.Dense(100, activation=\"selu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "gan = keras.models.Sequential([generator, discriminator])\n",
        "\n",
        "# Penting: Discriminator harus dikompilasi secara terpisah\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "discriminator.trainable = False # Saat melatih GAN utuh, discriminator tidak dilatih\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "\n",
        "print(\"Struktur GAN dasar siap.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Tantangan Melatih GAN\n",
        "\n",
        "Melatih GAN jauh lebih sulit daripada CNN biasa. Beberapa tantangan utamanya:\n",
        "1. **Nash Equilibrium**: Sulit menemukan keseimbangan antara dua pemain (Gen vs Disc).\n",
        "2. **Mode Collapse**: Generator hanya menghasilkan satu variasi gambar yang sangat mirip (karena berhasil menipu discriminator).\n",
        "3. **Ketidakstabilan**: Kehilangan (*loss*) discriminator bisa menjadi nol, sehingga generator tidak belajar apa-apa lagi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Kesimpulan Praktis\n",
        "\n",
        "- **Autoencoders**: Sangat baik untuk ekstraksi fitur, pengurangan dimensi, dan deteksi anomali.\n",
        "- **VAE**: Memungkinkan generasi data baru dengan kontrol pada *latent space*, namun gambar seringkali agak kabur.\n",
        "- **GAN**: Menghasilkan gambar yang sangat tajam dan realistis, namun memerlukan teknik regularisasi dan stabilitas tingkat tinggi (seperti DCGAN)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
