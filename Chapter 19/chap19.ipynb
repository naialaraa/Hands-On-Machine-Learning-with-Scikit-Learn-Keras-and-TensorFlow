{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
        "\n",
        "Pada chapter ini, pembahasan Machine Learning bergeser dari **membangun model** ke **mengoperasikan model di dunia nyata**.\n",
        "\n",
        "Jika pada chapter-chapter sebelumnya fokus utama adalah bagaimana melatih model agar akurat, maka chapter ini menjawab pertanyaan penting berikut:\n",
        "\n",
        "**\"Apa yang harus dilakukan setelah model selesai dilatih?\"**\n",
        "\n",
        "Chapter ini membahas bagaimana sebuah model TensorFlow dapat:\n",
        "- dideploy ke lingkungan produksi,\n",
        "- digunakan oleh berbagai sistem lain melalui API,\n",
        "- diperbarui secara berkala tanpa mengganggu layanan,\n",
        "- diskalakan untuk menangani trafik tinggi,\n",
        "- serta dipercepat menggunakan hardware seperti GPU dan TPU.\n",
        "\n",
        "Topik-topik ini sangat krusial karena pada praktiknya, nilai bisnis dari Machine Learning baru benar-benar terasa ketika model berhasil digunakan secara **andal, efisien, dan berkelanjutan** di production environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Dari Model Eksperimental ke Model Produksi\n",
        "\n",
        "Melatih model di notebook atau script Python hanyalah **langkah awal**.\n",
        "\n",
        "Dalam skenario nyata, sebuah sistem Machine Learning biasanya harus:\n",
        "- menerima data secara real-time,\n",
        "- memberikan prediksi dengan latensi rendah,\n",
        "- melayani banyak permintaan secara bersamaan,\n",
        "- diperbarui ketika data baru tersedia.\n",
        "\n",
        "Model yang akurat tetapi tidak dapat diintegrasikan dengan sistem lain **tidak memiliki nilai praktis**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sebagai contoh:\n",
        "- sistem rekomendasi berita harus terus diperbarui mengikuti tren terbaru,\n",
        "- model fraud detection harus merespons transaksi secara real-time,\n",
        "- model prediksi harus dapat digunakan oleh banyak aplikasi sekaligus.\n",
        "\n",
        "Kondisi ini menuntut pendekatan yang lebih sistematis terhadap **deployment, versioning, dan scalability**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Serving sebagai Layanan\n",
        "\n",
        "Pendekatan umum dalam production Machine Learning adalah **memisahkan model dari aplikasi utama**.\n",
        "\n",
        "Alih-alih menjalankan model langsung di dalam setiap aplikasi, model dibungkus sebagai sebuah **layanan (service)** yang dapat diakses melalui API.\n",
        "\n",
        "Pendekatan ini memberikan banyak keuntungan:\n",
        "- aplikasi lain tidak perlu mengetahui detail implementasi model,\n",
        "- model dapat diganti atau diperbarui tanpa mengubah kode aplikasi,\n",
        "- sistem dapat diskalakan secara independen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model serving biasanya dilakukan menggunakan:\n",
        "- REST API (berbasis HTTP dan JSON),\n",
        "- atau gRPC (berbasis protocol buffer, lebih efisien).\n",
        "\n",
        "Dengan cara ini, model menjadi **komponen terpisah** dalam arsitektur sistem, mirip dengan microservice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Tantangan Production Machine Learning\n",
        "\n",
        "Mendeploy model ke production membawa tantangan baru yang tidak muncul saat eksperimen:\n",
        "\n",
        "- **Model Versioning**: bagaimana mengganti model lama dengan model baru tanpa downtime,\n",
        "- **Rollback**: bagaimana kembali ke model sebelumnya jika versi baru bermasalah,\n",
        "- **A/B Testing**: bagaimana menguji dua model secara paralel,\n",
        "- **Scalability**: bagaimana melayani ribuan hingga jutaan request per detik,\n",
        "- **Monitoring**: bagaimana memantau performa dan degradasi model.\n",
        "\n",
        "Chapter ini akan membahas solusi praktis terhadap tantangan-tantangan tersebut menggunakan ekosistem TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Gambaran Umum Chapter 19\n",
        "\n",
        "Secara garis besar, chapter ini akan membahas:\n",
        "\n",
        "- penyimpanan model dalam format **SavedModel**,\n",
        "- deployment menggunakan **TensorFlow Serving**,\n",
        "- deployment ke cloud menggunakan **Google Cloud AI Platform**,\n",
        "- deployment ke mobile dan embedded device menggunakan **TensorFlow Lite**,\n",
        "- deployment ke browser menggunakan **TensorFlow.js**,\n",
        "- percepatan komputasi dengan **GPU**,\n",
        "- serta training terdistribusi menggunakan strategi TensorFlow.\n",
        "\n",
        "Topik-topik ini membentuk fondasi penting bagi sistem Machine Learning skala industri."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Saving and Exporting Models\n",
        "\n",
        "Sebelum sebuah model dapat dideploy ke production, model tersebut harus disimpan dalam format yang **standar, stabil, dan dapat digunakan lintas platform**.\n",
        "\n",
        "TensorFlow menyediakan format penyimpanan resmi bernama **SavedModel**, yang dirancang khusus untuk kebutuhan deployment skala besar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Mengapa Tidak Menyimpan Model sebagai File Python?\n",
        "\n",
        "Menyimpan model hanya sebagai kode Python tidak cukup untuk deployment karena:\n",
        "- bergantung pada environment Python tertentu,\n",
        "- sulit digunakan oleh bahasa atau sistem lain,\n",
        "- tidak menyimpan graph komputasi secara eksplisit.\n",
        "\n",
        "Production environment membutuhkan format yang **language-agnostic** dan **robust**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.2 SavedModel Format\n",
        "\n",
        "**SavedModel** adalah format standar TensorFlow untuk menyimpan:\n",
        "- arsitektur model,\n",
        "- bobot (weights),\n",
        "- computation graph,\n",
        "- signature fungsi untuk inference.\n",
        "\n",
        "Format ini dapat digunakan oleh:\n",
        "- TensorFlow Serving,\n",
        "- TensorFlow Lite,\n",
        "- TensorFlow.js,\n",
        "- serta berbagai runtime TensorFlow lainnya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SavedModel disimpan sebagai sebuah **direktori**, bukan satu file tunggal.\n",
        "\n",
        "Di dalam direktori tersebut biasanya terdapat:\n",
        "- folder `assets/` (opsional),\n",
        "- folder `variables/` (berisi bobot model),\n",
        "- file `saved_model.pb` (graph dan metadata model)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Menyimpan Model dengan Keras\n",
        "\n",
        "Keras menyediakan method `save()` untuk menyimpan model dalam format SavedModel.\n",
        "\n",
        "Contoh berikut menunjukkan cara menyimpan model hasil training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"my_saved_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perintah di atas akan membuat sebuah direktori bernama `my_saved_model/`.\n",
        "\n",
        "Direktori ini dapat langsung digunakan untuk deployment tanpa perlu kode training tambahan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4 Memuat Kembali Model\n",
        "\n",
        "Model yang telah disimpan dapat dimuat kembali menggunakan method `load_model()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_model = tf.keras.models.load_model(\"my_saved_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model yang dimuat kembali akan memiliki:\n",
        "- arsitektur yang sama,\n",
        "- bobot yang sama,\n",
        "- serta siap digunakan untuk inference.\n",
        "\n",
        "Hal ini memungkinkan pemisahan yang jelas antara fase **training** dan **serving**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.5 Model Signatures\n",
        "\n",
        "SavedModel juga menyimpan **signature**, yaitu definisi fungsi input dan output yang dapat dipanggil oleh sistem lain.\n",
        "\n",
        "Signature ini sangat penting untuk:\n",
        "- TensorFlow Serving,\n",
        "- pemanggilan model via REST atau gRPC,\n",
        "- integrasi dengan sistem non-Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dengan adanya signature, sistem eksternal tidak perlu mengetahui detail internal model.\n",
        "\n",
        "Mereka hanya perlu mengetahui:\n",
        "- nama fungsi,\n",
        "- format input,\n",
        "- format output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. TensorFlow Serving\n",
        "\n",
        "**TensorFlow Serving** adalah sistem khusus yang dirancang untuk **menyajikan model TensorFlow di lingkungan produksi**.\n",
        "\n",
        "Tujuan utama TensorFlow Serving adalah:\n",
        "- menyediakan inference dengan latensi rendah,\n",
        "- mendukung high throughput,\n",
        "- memungkinkan versioning dan hot-swapping model,\n",
        "- terintegrasi dengan format SavedModel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TensorFlow Serving memisahkan:\n",
        "- **training environment** (eksperimen, notebook, GPU training),\n",
        "- **serving environment** (server inference yang stabil dan efisien).\n",
        "\n",
        "Dengan pemisahan ini, sistem menjadi lebih modular dan mudah dikelola."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.1 Arsitektur TensorFlow Serving\n",
        "\n",
        "TensorFlow Serving berjalan sebagai **server mandiri** yang:\n",
        "- memuat model dari disk,\n",
        "- mengekspos endpoint API,\n",
        "- menangani request inference dari berbagai klien.\n",
        "\n",
        "Server ini tidak bergantung pada kode Python training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TensorFlow Serving mendukung dua protokol utama:\n",
        "- **REST API** (berbasis HTTP + JSON),\n",
        "- **gRPC** (berbasis Protocol Buffers, lebih cepat dan efisien).\n",
        "\n",
        "Pemilihan protokol tergantung pada kebutuhan performa dan kompleksitas sistem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.2 Menjalankan TensorFlow Serving dengan Docker\n",
        "\n",
        "Cara paling praktis untuk menjalankan TensorFlow Serving adalah menggunakan **Docker image resmi**.\n",
        "\n",
        "Docker memastikan:\n",
        "- environment konsisten,\n",
        "- dependensi terkelola,\n",
        "- deployment yang mudah direplikasi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "docker run -p 8501:8501 \\\n",
        "  --mount type=bind,source=/path/to/my_saved_model,target=/models/my_model \\\n",
        "  -e MODEL_NAME=my_model \\\n",
        "  tensorflow/serving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perintah di atas akan:\n",
        "- menjalankan TensorFlow Serving,\n",
        "- memuat model dari direktori lokal,\n",
        "- mengekspos REST API pada port 8501.\n",
        "\n",
        "Model dapat diakses tanpa menjalankan kode Python sama sekali."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.3 REST API untuk Inference\n",
        "\n",
        "Dengan REST API, inference dilakukan melalui HTTP POST request menggunakan format JSON.\n",
        "\n",
        "Endpoint standar TensorFlow Serving berbentuk:\n",
        "\n",
        "`http://localhost:8501/v1/models/<model_name>:predict`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "data = json.dumps({\n",
        "    \"instances\": X_test[:1].tolist()\n",
        "})\n",
        "\n",
        "response = requests.post(\n",
        "    \"http://localhost:8501/v1/models/my_model:predict\",\n",
        "    data=data\n",
        ")\n",
        "\n",
        "response.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Response dari server berisi hasil prediksi model dalam format JSON.\n",
        "\n",
        "Pendekatan ini memungkinkan berbagai bahasa pemrograman mengakses model yang sama."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.4 gRPC API\n",
        "\n",
        "Selain REST, TensorFlow Serving juga mendukung **gRPC**, yang:\n",
        "- lebih efisien dibandingkan JSON,\n",
        "- cocok untuk sistem dengan throughput tinggi,\n",
        "- sering digunakan pada arsitektur microservices berskala besar.\n",
        "\n",
        "Namun, gRPC lebih kompleks dalam implementasi dibandingkan REST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model Versioning\n",
        "\n",
        "Dalam lingkungan produksi, model Machine Learning **tidak bersifat statis**.\n",
        "\n",
        "Seiring waktu:\n",
        "- data baru tersedia,\n",
        "- distribusi data dapat berubah (data drift),\n",
        "- model lama dapat mengalami penurunan performa.\n",
        "\n",
        "Karena itu, sistem produksi harus mendukung **model versioning**, yaitu kemampuan menyimpan dan mengelola beberapa versi model secara bersamaan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1 Versioning pada TensorFlow Serving\n",
        "\n",
        "TensorFlow Serving secara alami mendukung versioning melalui struktur direktori.\n",
        "\n",
        "Setiap versi model disimpan dalam subdirektori bernomor, misalnya:\n",
        "\n",
        "```\n",
        "my_model/\n",
        " ├── 1/\n",
        " │    └── saved_model.pb\n",
        " ├── 2/\n",
        " │    └── saved_model.pb\n",
        "```\n",
        "\n",
        "Server akan otomatis memuat **versi terbaru** berdasarkan nomor versi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pendekatan ini memungkinkan:\n",
        "- update model tanpa downtime,\n",
        "- penyimpanan beberapa versi secara paralel,\n",
        "- kemudahan rollback jika terjadi masalah."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. A/B Testing untuk Model\n",
        "\n",
        "**A/B testing** adalah teknik untuk membandingkan dua atau lebih versi model secara bersamaan di lingkungan produksi.\n",
        "\n",
        "Tujuannya adalah mengevaluasi model baru secara **nyata** menggunakan data pengguna sebenarnya, bukan hanya data offline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dalam A/B testing model:\n",
        "- sebagian request diarahkan ke model lama (baseline),\n",
        "- sebagian request diarahkan ke model baru (candidate),\n",
        "- metrik performa dibandingkan secara statistik.\n",
        "\n",
        "Pendekatan ini membantu memastikan bahwa model baru benar-benar lebih baik sebelum diterapkan sepenuhnya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TensorFlow Serving dapat dikombinasikan dengan:\n",
        "- load balancer,\n",
        "- API gateway,\n",
        "- atau sistem routing eksternal,\n",
        "\n",
        "untuk mengatur distribusi trafik ke versi model yang berbeda."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Rollback Strategy\n",
        "\n",
        "Tidak semua deployment model berjalan mulus.\n",
        "\n",
        "Model baru bisa saja:\n",
        "- menghasilkan prediksi yang tidak stabil,\n",
        "- meningkatkan latensi,\n",
        "- atau menurunkan performa bisnis.\n",
        "\n",
        "Karena itu, sistem produksi harus memiliki **strategi rollback** yang cepat dan aman."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dengan versioning di TensorFlow Serving, rollback dapat dilakukan dengan:\n",
        "- menghentikan penggunaan versi terbaru,\n",
        "- mengarahkan kembali trafik ke versi sebelumnya,\n",
        "- tanpa perlu retraining atau rebuild sistem.\n",
        "\n",
        "Strategi ini sangat penting untuk menjaga **reliability** sistem Machine Learning di production."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Cloud Deployment\n",
        "\n",
        "Untuk sistem Machine Learning berskala besar, deployment lokal sering kali tidak cukup.\n",
        "\n",
        "Cloud computing memungkinkan:\n",
        "- skalabilitas otomatis,\n",
        "- ketersediaan tinggi (high availability),\n",
        "- integrasi dengan berbagai layanan data dan monitoring.\n",
        "\n",
        "Pada chapter ini, contoh cloud deployment difokuskan pada **Google Cloud AI Platform** (sekarang dikenal sebagai Vertex AI)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10.1 Mengapa Menggunakan Cloud untuk ML?\n",
        "\n",
        "Beberapa alasan utama penggunaan cloud dalam deployment Machine Learning:\n",
        "- model dapat diakses dari mana saja,\n",
        "- sistem dapat menangani lonjakan trafik secara otomatis,\n",
        "- tidak perlu mengelola server fisik sendiri,\n",
        "- mudah terintegrasi dengan pipeline data dan monitoring.\n",
        "\n",
        "Pendekatan ini sangat umum pada sistem ML di industri."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10.2 AI Platform / Vertex AI Overview\n",
        "\n",
        "Google Cloud AI Platform menyediakan layanan end-to-end untuk Machine Learning, mulai dari:\n",
        "- training model,\n",
        "- hyperparameter tuning,\n",
        "- deployment model,\n",
        "- hingga monitoring performa model.\n",
        "\n",
        "Platform ini dirancang agar model TensorFlow dapat dideploy tanpa perlu membangun sistem serving dari nol."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10.3 Menyiapkan Model untuk Cloud Deployment\n",
        "\n",
        "Sama seperti TensorFlow Serving, model yang akan dideploy ke cloud harus disimpan dalam format **SavedModel**.\n",
        "\n",
        "Format ini memastikan kompatibilitas dengan layanan managed serving di cloud."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model kemudian diunggah ke **Cloud Storage (GCS)**, yang berfungsi sebagai repositori model terpusat.\n",
        "\n",
        "Setiap versi model biasanya disimpan pada path yang berbeda untuk mendukung versioning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# contoh struktur path di Google Cloud Storage\n",
        "# gs://my-bucket/my_model/1/\n",
        "# gs://my-bucket/my_model/2/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10.4 Deploying Model to AI Platform\n",
        "\n",
        "Setelah model berada di Cloud Storage, model dapat dideploy sebagai **endpoint**.\n",
        "\n",
        "Endpoint ini akan:\n",
        "- memuat model secara otomatis,\n",
        "- menangani request inference,\n",
        "- menskalakan resource sesuai kebutuhan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Deployment biasanya dilakukan menggunakan:\n",
        "- Google Cloud Console,\n",
        "- atau command-line tool `gcloud`.\n",
        "\n",
        "Pendekatan ini memisahkan proses deployment dari kode aplikasi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10.5 Keuntungan Managed ML Services\n",
        "\n",
        "Dengan menggunakan layanan managed seperti AI Platform, tim ML mendapatkan beberapa keuntungan:\n",
        "- tidak perlu mengelola server inference,\n",
        "- autoscaling otomatis,\n",
        "- integrasi keamanan dan logging bawaan,\n",
        "- fokus pada pengembangan model, bukan infrastruktur.\n",
        "\n",
        "Namun, pendekatan ini juga memiliki trade-off seperti biaya dan ketergantungan pada vendor cloud tertentu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Deployment ke Mobile & Embedded Devices\n",
        "\n",
        "Tidak semua model Machine Learning dijalankan di server cloud.\n",
        "\n",
        "Dalam banyak aplikasi nyata, model perlu dijalankan langsung di **perangkat pengguna**, seperti:\n",
        "- smartphone,\n",
        "- IoT devices,\n",
        "- embedded systems,\n",
        "- edge devices.\n",
        "\n",
        "Untuk kebutuhan ini, TensorFlow menyediakan **TensorFlow Lite (TFLite)**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11.1 Mengapa On-Device ML?\n",
        "\n",
        "Menjalankan model langsung di perangkat memiliki beberapa keuntungan:\n",
        "- latensi sangat rendah (tidak perlu request ke server),\n",
        "- privasi data lebih terjaga,\n",
        "- aplikasi tetap berfungsi tanpa koneksi internet,\n",
        "- beban server dan biaya cloud berkurang.\n",
        "\n",
        "Namun, perangkat memiliki keterbatasan memori, daya, dan komputasi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11.2 TensorFlow Lite\n",
        "\n",
        "**TensorFlow Lite** adalah versi ringan dari TensorFlow yang dirancang khusus untuk perangkat dengan resource terbatas.\n",
        "\n",
        "TFLite menyediakan:\n",
        "- format model yang lebih kecil,\n",
        "- runtime inference yang cepat,\n",
        "- dukungan hardware acceleration (CPU, GPU, DSP, NPU).\n",
        "\n",
        "Model TFLite biasanya dihasilkan dari model TensorFlow standar melalui proses konversi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11.3 Mengonversi Model ke TensorFlow Lite\n",
        "\n",
        "Model yang telah disimpan dalam format SavedModel dapat dikonversi ke format TFLite menggunakan **TFLiteConverter**.\n",
        "\n",
        "Proses ini menghasilkan file `.tflite` yang siap digunakan di perangkat mobile atau embedded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"my_saved_model\")\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "File `model.tflite` yang dihasilkan memiliki ukuran jauh lebih kecil dibandingkan model TensorFlow penuh.\n",
        "\n",
        "File ini dapat langsung disertakan dalam aplikasi Android, iOS, atau firmware embedded."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11.4 Model Optimization\n",
        "\n",
        "Untuk meningkatkan performa dan mengurangi ukuran model, TensorFlow Lite mendukung berbagai teknik optimisasi, seperti:\n",
        "- **quantization** (mengubah bobot dari float32 ke int8),\n",
        "- pruning,\n",
        "- operator fusion.\n",
        "\n",
        "Optimisasi ini penting untuk deployment pada perangkat dengan memori dan daya terbatas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Quantization, misalnya, dapat:\n",
        "- memperkecil ukuran model secara signifikan,\n",
        "- mempercepat inference,\n",
        "- dengan penurunan akurasi yang minimal jika dilakukan dengan benar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11.5 Use Cases TensorFlow Lite\n",
        "\n",
        "Beberapa contoh penggunaan TensorFlow Lite:\n",
        "- face detection di smartphone,\n",
        "- speech recognition offline,\n",
        "- image classification pada IoT camera,\n",
        "- sensor data analysis pada embedded device.\n",
        "\n",
        "Pendekatan ini dikenal sebagai **edge ML**, dan semakin penting seiring berkembangnya IoT dan mobile computing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Deployment di Browser dengan TensorFlow.js\n",
        "\n",
        "Selain server dan perangkat mobile, model Machine Learning juga dapat dijalankan langsung di **browser pengguna**.\n",
        "\n",
        "Pendekatan ini dimungkinkan melalui **TensorFlow.js**, sebuah library JavaScript yang memungkinkan:\n",
        "- inference model ML langsung di browser,\n",
        "- training model sederhana di sisi klien,\n",
        "- pemanfaatan GPU melalui WebGL atau WebGPU.\n",
        "\n",
        "Deployment di browser membuka peluang besar untuk aplikasi interaktif dan real-time tanpa server inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12.1 Keuntungan Deployment di Browser\n",
        "\n",
        "Menjalankan model di browser memiliki beberapa kelebihan:\n",
        "- tidak memerlukan backend inference,\n",
        "- latensi sangat rendah,\n",
        "- privasi data lebih terjaga karena data tidak dikirim ke server,\n",
        "- mudah diakses melalui web.\n",
        "\n",
        "Namun, pendekatan ini juga dibatasi oleh kemampuan hardware perangkat pengguna."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12.2 TensorFlow.js Overview\n",
        "\n",
        "**TensorFlow.js** memungkinkan pengembang untuk:\n",
        "- memuat model TensorFlow atau Keras di JavaScript,\n",
        "- menjalankan inference menggunakan CPU atau GPU browser,\n",
        "- membangun aplikasi ML end-to-end berbasis web.\n",
        "\n",
        "TensorFlow.js mendukung model hasil konversi dari SavedModel atau Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12.3 Mengonversi Model ke TensorFlow.js\n",
        "\n",
        "Model TensorFlow dapat dikonversi ke format TensorFlow.js menggunakan tool `tensorflowjs_converter`.\n",
        "\n",
        "Tool ini akan mengubah model menjadi file JSON dan binary weights yang dapat dimuat di browser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tensorflowjs_converter \\\n",
        "  --input_format=tf_saved_model \\\n",
        "  --output_format=tfjs_graph_model \\\n",
        "  my_saved_model \\\n",
        "  tfjs_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setelah konversi, direktori `tfjs_model/` akan berisi:\n",
        "- file model.json,\n",
        "- file binary weights.\n",
        "\n",
        "File-file ini dapat disajikan menggunakan web server biasa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12.4 Menggunakan Model di JavaScript\n",
        "\n",
        "Model TensorFlow.js dapat dimuat dan digunakan langsung di kode JavaScript."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "// Contoh JavaScript (konseptual)\n",
        "const model = await tf.loadGraphModel('tfjs_model/model.json');\n",
        "const prediction = model.predict(inputTensor);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pendekatan ini memungkinkan integrasi Machine Learning langsung ke aplikasi web modern.\n",
        "\n",
        "TensorFlow.js banyak digunakan untuk aplikasi seperti:\n",
        "- gesture recognition,\n",
        "- image classification berbasis webcam,\n",
        "- interactive data visualization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Hardware Acceleration\n",
        "\n",
        "Seiring bertambahnya ukuran dataset dan kompleksitas model, training dan inference pada CPU saja sering kali menjadi tidak efisien.\n",
        "\n",
        "Untuk mengatasi hal ini, TensorFlow mendukung **hardware acceleration** menggunakan perangkat khusus seperti:\n",
        "- **GPU (Graphics Processing Unit)**,\n",
        "- **TPU (Tensor Processing Unit)**.\n",
        "\n",
        "Perangkat ini dirancang untuk melakukan komputasi paralel dalam jumlah besar, yang sangat cocok untuk operasi linear algebra pada neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13.1 GPU Acceleration\n",
        "\n",
        "GPU sangat efektif untuk neural network karena:\n",
        "- mampu menjalankan ribuan operasi paralel,\n",
        "- sangat efisien untuk matrix multiplication,\n",
        "- didukung luas oleh framework deep learning modern.\n",
        "\n",
        "TensorFlow dapat secara otomatis mendeteksi dan menggunakan GPU jika tersedia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dengan GPU, proses training yang sebelumnya memakan waktu berjam-jam di CPU dapat dipercepat menjadi hitungan menit.\n",
        "\n",
        "Namun, penggunaan GPU juga membutuhkan:\n",
        "- driver dan library khusus (CUDA, cuDNN),\n",
        "- manajemen memori yang lebih kompleks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13.2 TPU (Tensor Processing Unit)\n",
        "\n",
        "**TPU** adalah hardware khusus yang dikembangkan oleh Google untuk mempercepat workload Machine Learning.\n",
        "\n",
        "TPU dirancang untuk:\n",
        "- operasi tensor skala besar,\n",
        "- training dan inference neural network secara efisien,\n",
        "- integrasi mendalam dengan TensorFlow.\n",
        "\n",
        "TPU umumnya tersedia melalui layanan cloud seperti Google Cloud."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Penggunaan TPU memungkinkan:\n",
        "- training model besar dalam waktu yang jauh lebih singkat,\n",
        "- skala training yang sulit dicapai dengan satu GPU.\n",
        "\n",
        "Namun, TPU memiliki keterbatasan:\n",
        "- hanya mendukung operasi tertentu,\n",
        "- kurang fleksibel dibandingkan GPU untuk eksperimen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Distributed Training\n",
        "\n",
        "Untuk dataset dan model yang sangat besar, satu perangkat komputasi saja sering kali tidak cukup.\n",
        "\n",
        "**Distributed training** memungkinkan training model dilakukan secara paralel di:\n",
        "- beberapa GPU,\n",
        "- beberapa mesin,\n",
        "- atau kombinasi keduanya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TensorFlow menyediakan **tf.distribute.Strategy** untuk mempermudah distributed training.\n",
        "\n",
        "Beberapa strategi yang umum digunakan:\n",
        "- `MirroredStrategy`: training paralel pada banyak GPU di satu mesin,\n",
        "- `MultiWorkerMirroredStrategy`: training pada banyak mesin,\n",
        "- `TPUStrategy`: training pada TPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 14.1 Contoh Penggunaan MirroredStrategy\n",
        "\n",
        "Contoh berikut menunjukkan bagaimana model Keras dapat dilatih menggunakan beberapa GPU secara transparan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with strategy.scope():\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dense(300, activation=\"relu\"),\n",
        "        keras.layers.Dense(100, activation=\"relu\"),\n",
        "        keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    model.compile(\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        optimizer=\"sgd\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dengan pendekatan ini:\n",
        "- kode training hampir tidak berubah,\n",
        "- TensorFlow mengelola sinkronisasi gradien secara otomatis,\n",
        "- performa training meningkat secara signifikan.\n",
        "\n",
        "Distributed training merupakan komponen penting dalam sistem Machine Learning berskala industri."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Closing Summary (Chapter 19)\n",
        "\n",
        "Chapter 19 membahas aspek yang sangat krusial dalam Machine Learning modern, yaitu **bagaimana membawa model dari tahap eksperimen ke lingkungan produksi berskala besar**.\n",
        "\n",
        "Jika chapter sebelumnya berfokus pada bagaimana membangun dan melatih model yang akurat, maka chapter ini menekankan bagaimana model tersebut dapat digunakan secara nyata, andal, dan berkelanjutan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Beberapa poin utama yang dipelajari dalam chapter ini meliputi:\n",
        "- penyimpanan model menggunakan format **SavedModel** sebagai standar deployment,\n",
        "- penyajian model menggunakan **TensorFlow Serving** dengan REST dan gRPC,\n",
        "- pengelolaan **model versioning**, A/B testing, dan rollback,\n",
        "- deployment model ke cloud menggunakan layanan managed seperti **Google Cloud AI Platform**,\n",
        "- deployment ke perangkat mobile dan embedded menggunakan **TensorFlow Lite**,\n",
        "- deployment ke browser menggunakan **TensorFlow.js**,\n",
        "- percepatan komputasi dengan **GPU** dan **TPU**,\n",
        "- serta training terdistribusi menggunakan strategi TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Chapter ini menegaskan bahwa keberhasilan sistem Machine Learning di dunia nyata tidak hanya ditentukan oleh akurasi model, tetapi juga oleh:\n",
        "- stabilitas sistem,\n",
        "- kemampuan untuk diskalakan,\n",
        "- kemudahan pemeliharaan,\n",
        "- serta kesiapan menghadapi perubahan data dan kebutuhan bisnis.\n",
        "\n",
        "Dengan kata lain, **Machine Learning di industri adalah kombinasi antara data science dan software engineering**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pemahaman chapter ini sangat penting bagi peran seperti:\n",
        "- Machine Learning Engineer,\n",
        "- Data Engineer,\n",
        "- AI Engineer,\n",
        "- dan praktisi ML yang ingin membangun sistem end-to-end.\n",
        "\n",
        "Chapter 19 menjadi penutup yang kuat untuk menunjukkan bagaimana TensorFlow tidak hanya digunakan untuk eksperimen, tetapi juga untuk membangun sistem Machine Learning **siap produksi dan skala industri**."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
