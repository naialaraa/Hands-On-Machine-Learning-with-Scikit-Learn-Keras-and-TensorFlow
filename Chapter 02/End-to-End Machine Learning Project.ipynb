{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 2: End-to-End Machine Learning Project\n",
        "\n",
        "Pada chapter ini, kita akan mempelajari bagaimana sebuah proyek Machine Learning dikerjakan **secara menyeluruh dari awal hingga akhir** (*end-to-end*).\n",
        "\n",
        "Berbeda dengan chapter sebelumnya yang berfokus pada konsep dasar Machine Learning, chapter ini menempatkan kita pada **skenario dunia nyata**, seolah-olah kita adalah seorang data scientist yang baru direkrut oleh sebuah perusahaan.\n",
        "\n",
        "Tujuan utama dari chapter ini adalah memahami **alur kerja sistematis** dalam proyek Machine Learning, mulai dari memahami masalah bisnis, mengumpulkan data, melakukan eksplorasi data, mempersiapkan data, memilih model, hingga mengevaluasi dan mempersiapkan sistem untuk digunakan secara nyata.\n",
        "\n",
        "Pendekatan end-to-end ini sangat penting karena dalam praktik profesional, tantangan terbesar Machine Learning sering kali bukan pada algoritma, melainkan pada **data, asumsi, dan proses pengambilan keputusan**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Look at the Big Picture\n",
        "\n",
        "Langkah pertama dalam proyek Machine Learning adalah memahami gambaran besar dari masalah yang ingin diselesaikan.\n",
        "\n",
        "Pada chapter ini, kita berperan sebagai data scientist di sebuah perusahaan real estate yang ingin membangun sistem prediksi **median harga rumah** di California berdasarkan data sensus.\n",
        "\n",
        "Model yang dibangun nantinya akan digunakan sebagai bagian dari sistem yang lebih besar untuk membantu pengambilan keputusan investasi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 Framing the Problem\n",
        "\n",
        "Sebelum menulis satu baris kode pun, sangat penting untuk memahami **apa sebenarnya masalah yang ingin diselesaikan**.\n",
        "\n",
        "Beberapa pertanyaan kunci yang perlu dijawab:\n",
        "- Apakah ini masalah *supervised* atau *unsupervised learning*?\n",
        "- Apakah ini tugas *classification* atau *regression*?\n",
        "- Apakah sistem perlu belajar secara *batch* atau *online*?\n",
        "\n",
        "Dalam kasus ini:\n",
        "- Data memiliki label (harga rumah) → **Supervised Learning**\n",
        "- Target berupa nilai kontinu → **Regression**\n",
        "- Menggunakan banyak fitur untuk memprediksi satu nilai → **Multiple Regression**\n",
        "- Data relatif statis dan tidak terlalu besar → **Batch Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 Select a Performance Measure\n",
        "\n",
        "Setelah masalah diformulasikan dengan jelas, langkah berikutnya adalah menentukan **metrik evaluasi**.\n",
        "\n",
        "Untuk masalah regresi, salah satu metrik yang paling umum digunakan adalah **Root Mean Square Error (RMSE)**.\n",
        "\n",
        "RMSE memberikan gambaran seberapa besar kesalahan prediksi model secara rata-rata, dengan memberikan penalti lebih besar pada error yang besar.\n",
        "\n",
        "Secara intuitif:\n",
        "- RMSE kecil → prediksi model mendekati nilai sebenarnya\n",
        "- RMSE besar → model sering membuat kesalahan besar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Selain RMSE, terkadang digunakan juga **Mean Absolute Error (MAE)**.\n",
        "\n",
        "Perbedaan utama:\n",
        "- RMSE lebih sensitif terhadap *outlier*\n",
        "- MAE lebih robust terhadap *outlier*\n",
        "\n",
        "Pemilihan metrik harus disesuaikan dengan konteks bisnis dan karakteristik data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Get the Data\n",
        "\n",
        "Setelah memahami gambaran besar dan tujuan proyek, langkah berikutnya adalah **mengumpulkan dan memuat data**.\n",
        "\n",
        "Pada proyek ini, kita menggunakan dataset **California Housing** yang berisi informasi sensus mengenai perumahan di California.\n",
        "\n",
        "Dataset ini mencakup berbagai fitur seperti lokasi geografis, jumlah kamar, jumlah penduduk, dan median pendapatan, yang semuanya berpotensi memengaruhi harga rumah."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Create the Workspace\n",
        "\n",
        "Sebelum memuat data, kita perlu menyiapkan *workspace* yang rapi.\n",
        "\n",
        "Langkah ini mencakup:\n",
        "- mengimpor library yang dibutuhkan,\n",
        "- menyiapkan struktur folder untuk menyimpan data,\n",
        "- memastikan eksperimen dapat direproduksi.\n",
        "\n",
        "Pendekatan ini sangat penting dalam proyek Machine Learning nyata agar proses kerja terorganisir dan dapat diulang."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Kode di atas mengimpor modul standar Python yang digunakan untuk:\n",
        "- mengelola direktori,\n",
        "- mengekstrak file terkompresi,\n",
        "- serta mengunduh data dari internet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Downloading the Data\n",
        "\n",
        "Dataset California Housing disediakan dalam bentuk file terkompresi. Kita akan membuat fungsi untuk:\n",
        "- mengunduh dataset jika belum tersedia,\n",
        "- mengekstraknya ke folder lokal.\n",
        "\n",
        "Pendekatan ini memastikan bahwa notebook dapat dijalankan ulang tanpa harus mengunduh data berulang kali."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    os.makedirs(housing_path, exist_ok=True)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fungsi `fetch_housing_data()` bertanggung jawab untuk mengunduh dan mengekstrak dataset.\n",
        "\n",
        "Dengan membungkus proses ini ke dalam fungsi, kita menjaga kode tetap bersih dan mudah digunakan kembali."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fetch_housing_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setelah fungsi dijalankan, dataset akan tersedia secara lokal di direktori `datasets/housing`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Loading the Data\n",
        "\n",
        "Setelah data tersedia secara lokal, langkah berikutnya adalah memuat data ke dalam struktur yang mudah dianalisis.\n",
        "\n",
        "Pada proyek ini, kita menggunakan **pandas DataFrame**, yang menyediakan berbagai fungsi untuk eksplorasi dan manipulasi data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "housing = load_housing_data()\n",
        "housing.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DataFrame di atas menampilkan lima baris pertama dari dataset California Housing.\n",
        "\n",
        "Setiap baris merepresentasikan satu distrik sensus, dan setiap kolom merepresentasikan fitur atau target yang akan digunakan dalam proses Machine Learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Take a Quick Look at the Data Structure\n",
        "\n",
        "Setelah data dimuat, langkah penting berikutnya adalah **memahami struktur data secara umum**.\n",
        "\n",
        "Pada tahap ini, tujuan kita bukan melakukan analisis mendalam, melainkan:\n",
        "- mengetahui jumlah baris dan kolom,\n",
        "- memahami tipe data setiap fitur,\n",
        "- mengidentifikasi adanya nilai yang hilang (*missing values*),\n",
        "- serta mengenali fitur kategorikal dan numerik.\n",
        "\n",
        "Langkah ini membantu kita merencanakan proses pembersihan dan persiapan data pada tahap selanjutnya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Data Overview with `info()`\n",
        "\n",
        "Fungsi `info()` pada pandas memberikan ringkasan singkat mengenai DataFrame, termasuk jumlah non-null value dan tipe data setiap kolom."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "housing.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dari output `info()`, kita dapat mengamati bahwa sebagian besar fitur bertipe numerik.\n",
        "\n",
        "Namun, terdapat satu fitur bertipe objek, yaitu `ocean_proximity`, yang menunjukkan bahwa fitur tersebut bersifat **kategorikal**.\n",
        "\n",
        "Selain itu, terlihat bahwa kolom `total_bedrooms` memiliki jumlah non-null value yang lebih sedikit, yang mengindikasikan adanya **nilai yang hilang**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Descriptive Statistics\n",
        "\n",
        "Untuk mendapatkan gambaran statistik dasar dari fitur numerik, kita dapat menggunakan metode `describe()`.\n",
        "\n",
        "Metode ini menampilkan informasi seperti nilai minimum, maksimum, rata-rata, dan standar deviasi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "housing.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Statistik deskriptif ini memberikan banyak informasi penting, misalnya:\n",
        "- rentang nilai setiap fitur,\n",
        "- adanya fitur dengan skala yang sangat berbeda,\n",
        "- serta kemungkinan keberadaan outlier.\n",
        "\n",
        "Perbedaan skala ini menjadi alasan mengapa **feature scaling** sering diperlukan sebelum melatih model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Categorical Attribute: `ocean_proximity`\n",
        "\n",
        "Kolom `ocean_proximity` merupakan satu-satunya fitur kategorikal dalam dataset ini.\n",
        "\n",
        "Untuk memahami distribusi kategorinya, kita dapat menghitung jumlah kemunculan setiap kategori."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "housing[\"ocean_proximity\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Distribusi kategori ini menunjukkan bagaimana distrik sensus tersebar berdasarkan kedekatannya dengan laut.\n",
        "\n",
        "Informasi ini penting karena lokasi geografis memiliki pengaruh besar terhadap harga rumah, sehingga fitur ini kemungkinan besar memiliki kontribusi signifikan terhadap prediksi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create a Test Set\n",
        "\n",
        "Sebelum melakukan eksplorasi data lebih lanjut atau melatih model, sangat penting untuk **memisahkan test set sejak awal**.\n",
        "\n",
        "Tujuan utama dari test set adalah untuk memberikan estimasi performa model pada data yang benar-benar belum pernah dilihat selama proses training.\n",
        "\n",
        "Jika test set digunakan terlalu dini atau terpapar selama eksplorasi, maka evaluasi akhir model dapat menjadi bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Random Sampling\n",
        "\n",
        "Pendekatan paling sederhana untuk membagi data adalah **random sampling**, yaitu memilih sebagian data secara acak sebagai test set.\n",
        "\n",
        "Namun, pendekatan ini memiliki kelemahan, terutama ketika dataset relatif kecil atau memiliki distribusi fitur yang tidak merata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
        "len(train_set), len(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pembagian ini menghasilkan sekitar 80% data untuk training dan 20% data untuk testing.\n",
        "\n",
        "Penggunaan `random_state` memastikan bahwa pembagian data bersifat **reproducible**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Stratified Sampling\n",
        "\n",
        "Random sampling dapat menghasilkan test set yang tidak merepresentasikan populasi dengan baik.\n",
        "\n",
        "Untuk mengatasi hal ini, digunakan **stratified sampling**, yaitu memastikan bahwa distribusi fitur penting tetap terjaga pada training dan test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dalam proyek ini, fitur `median_income` dianggap sangat penting untuk prediksi harga rumah.\n",
        "\n",
        "Oleh karena itu, kita membuat kategori pendapatan dan menggunakan kategori ini sebagai dasar stratifikasi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "housing[\"income_cat\"] = pd.cut(\n",
        "    housing[\"median_income\"],\n",
        "    bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
        "    labels=[1, 2, 3, 4, 5]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fitur `income_cat` mengelompokkan nilai `median_income` ke dalam beberapa kategori diskrit.\n",
        "\n",
        "Pendekatan ini membantu memastikan bahwa distribusi pendapatan tetap konsisten antara training dan test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "\n",
        "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
        "    strat_train_set = housing.loc[train_index]\n",
        "    strat_test_set = housing.loc[test_index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dengan stratified sampling, training dan test set memiliki distribusi `income_cat` yang sangat mirip dengan dataset asli.\n",
        "\n",
        "Pendekatan ini menghasilkan evaluasi model yang lebih adil dan representatif."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setelah pembagian data selesai, fitur `income_cat` tidak lagi dibutuhkan dan dapat dihapus untuk mencegah *data leakage*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for set_ in (strat_train_set, strat_test_set):\n",
        "    set_.drop(\"income_cat\", axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Discover and Visualize the Data to Gain Insights\n",
        "\n",
        "Setelah training dan test set dipisahkan dengan benar, kita dapat mulai melakukan **eksplorasi data secara lebih mendalam**.\n",
        "\n",
        "Tahap ini bertujuan untuk:\n",
        "- memahami pola dan distribusi data,\n",
        "- mengidentifikasi hubungan antar fitur,\n",
        "- menemukan anomali atau outlier,\n",
        "- serta mendapatkan intuisi awal tentang faktor yang memengaruhi harga rumah.\n",
        "\n",
        "Seluruh eksplorasi dilakukan **hanya pada training set**, untuk menghindari *data leakage*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Untuk mempermudah eksplorasi, kita membuat salinan dari training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "housing = strat_train_set.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Visualizing Geographical Data\n",
        "\n",
        "Karena dataset California Housing memiliki informasi geografis (longitude dan latitude), kita dapat memvisualisasikan lokasi distrik sensus untuk melihat pola spasial.\n",
        "\n",
        "Visualisasi ini sering kali memberikan wawasan yang sulit diperoleh hanya dari tabel angka."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot di atas menunjukkan kepadatan distrik sensus di California. Area dengan titik yang lebih padat merepresentasikan wilayah dengan populasi lebih tinggi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Visualizing Housing Prices\n",
        "\n",
        "Untuk mendapatkan insight yang lebih kaya, kita dapat memvisualisasikan harga rumah dengan:\n",
        "- ukuran titik merepresentasikan populasi,\n",
        "- warna titik merepresentasikan median harga rumah."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "housing.plot(\n",
        "    kind=\"scatter\",\n",
        "    x=\"longitude\",\n",
        "    y=\"latitude\",\n",
        "    alpha=0.4,\n",
        "    s=housing[\"population\"] / 100,\n",
        "    label=\"population\",\n",
        "    figsize=(10, 7),\n",
        "    c=\"median_house_value\",\n",
        "    cmap=plt.get_cmap(\"jet\"),\n",
        "    colorbar=True,\n",
        ")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualisasi ini memperlihatkan bahwa harga rumah cenderung lebih tinggi di wilayah pesisir dan area metropolitan besar.\n",
        "\n",
        "Insight ini menegaskan bahwa **lokasi geografis merupakan faktor penting** dalam prediksi harga rumah."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Looking for Correlations\n",
        "\n",
        "Setelah visualisasi, langkah selanjutnya adalah mengukur hubungan antar fitur secara kuantitatif menggunakan **koefisien korelasi**.\n",
        "\n",
        "Korelasi membantu kita memahami fitur mana yang memiliki hubungan paling kuat dengan target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_matrix = housing.corr()\n",
        "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hasil korelasi menunjukkan bahwa `median_income` memiliki korelasi paling kuat dengan `median_house_value`.\n",
        "\n",
        "Informasi ini sangat berguna dalam proses feature engineering dan pemilihan model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4 Scatter Matrix\n",
        "\n",
        "Untuk memvisualisasikan hubungan antar beberapa fitur penting sekaligus, kita dapat menggunakan **scatter matrix**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
        "              \"housing_median_age\"]\n",
        "scatter_matrix(housing[attributes], figsize=(12, 8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Scatter matrix memperjelas hubungan linear antara `median_income` dan `median_house_value`, serta membantu mengidentifikasi pola non-linear dan outlier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Experimenting with Attribute Combinations\n",
        "\n",
        "Pada tahap ini, kita mulai melakukan **feature engineering**, yaitu menciptakan fitur baru dari fitur yang sudah ada.\n",
        "\n",
        "Tujuan utama feature engineering adalah mengekspresikan informasi dalam data dengan cara yang lebih bermakna bagi model Machine Learning.\n",
        "\n",
        "Sering kali, fitur hasil kombinasi justru memiliki korelasi yang lebih kuat terhadap target dibandingkan fitur mentahnya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1 Creating New Attributes\n",
        "\n",
        "Dalam dataset perumahan ini, beberapa fitur mentah kurang informatif jika digunakan secara terpisah.\n",
        "\n",
        "Sebagai contoh:\n",
        "- `total_rooms` tidak memperhitungkan jumlah rumah tangga\n",
        "- `population` tidak mempertimbangkan ukuran distrik\n",
        "\n",
        "Oleh karena itu, kita dapat membuat fitur rasio yang lebih representatif."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "housing[\"rooms_per_household\"] = housing[\"total_rooms\"] / housing[\"households\"]\n",
        "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"] / housing[\"total_rooms\"]\n",
        "housing[\"population_per_household\"] = housing[\"population\"] / housing[\"households\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fitur-fitur baru ini memberikan perspektif yang lebih kontekstual, misalnya:\n",
        "- ukuran rumah rata-rata,\n",
        "- kepadatan penduduk per rumah tangga,\n",
        "- proporsi kamar tidur terhadap total kamar.\n",
        "\n",
        "Fitur semacam ini sering kali lebih berkorelasi dengan harga rumah."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 Checking Correlation with New Attributes\n",
        "\n",
        "Setelah fitur baru dibuat, kita perlu mengevaluasi apakah fitur tersebut действительно memberikan informasi tambahan.\n",
        "\n",
        "Salah satu cara cepat adalah dengan menghitung kembali korelasi terhadap target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_matrix = housing.corr()\n",
        "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hasil korelasi menunjukkan bahwa beberapa fitur hasil rekayasa memiliki korelasi yang cukup kuat dengan `median_house_value`.\n",
        "\n",
        "Hal ini menegaskan bahwa **feature engineering merupakan langkah krusial** dalam meningkatkan performa model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Prepare the Data for Machine Learning Algorithms\n",
        "\n",
        "Setelah eksplorasi data dan feature engineering, langkah selanjutnya adalah **mempersiapkan data agar siap digunakan oleh algoritma Machine Learning**.\n",
        "\n",
        "Tahap ini sangat krusial karena sebagian besar algoritma Machine Learning **tidak dapat menangani data mentah secara langsung**, terutama jika terdapat nilai yang hilang atau fitur kategorikal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1 Separating Predictors and Labels\n",
        "\n",
        "Langkah pertama dalam data preparation adalah memisahkan fitur (*predictors*) dan target (*labels*).\n",
        "\n",
        "Target dalam proyek ini adalah `median_house_value`, sehingga kolom tersebut harus dipisahkan dari fitur lainnya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
        "housing_labels = strat_train_set[\"median_house_value\"].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dengan pemisahan ini, kita memastikan bahwa proses preprocessing tidak secara tidak sengaja menggunakan informasi dari target."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 Data Cleaning (Handling Missing Values)\n",
        "\n",
        "Sebagaimana telah diamati sebelumnya, kolom `total_bedrooms` memiliki beberapa nilai yang hilang.\n",
        "\n",
        "Terdapat beberapa strategi untuk menangani nilai hilang:\n",
        "- menghapus baris yang mengandung nilai hilang,\n",
        "- menghapus kolom yang mengandung nilai hilang,\n",
        "- mengganti nilai hilang dengan nilai statistik tertentu (misalnya median).\n",
        "\n",
        "Pada proyek ini, kita memilih pendekatan **imputasi median**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(strategy=\"median\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imputer hanya dapat diterapkan pada fitur numerik. Oleh karena itu, kita perlu memisahkan fitur numerik dari fitur kategorikal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "housing_num = housing.drop(\"ocean_proximity\", axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imputer.fit(housing_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Median dari setiap fitur numerik dihitung dari training set dan akan digunakan untuk menggantikan nilai yang hilang."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = imputer.transform(housing_num)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setelah proses imputasi, dataset numerik tidak lagi mengandung nilai yang hilang dan siap untuk tahap preprocessing berikutnya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Untuk kemudahan analisis, hasil transformasi dapat dikembalikan ke dalam bentuk DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "housing_tr = pd.DataFrame(X, columns=housing_num.columns, index=housing_num.index)\n",
        "housing_tr.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Handling Text and Categorical Attributes\n",
        "\n",
        "Sebagian besar algoritma Machine Learning hanya dapat bekerja dengan **fitur numerik**. Oleh karena itu, fitur kategorikal perlu dikonversi ke representasi numerik sebelum digunakan untuk training.\n",
        "\n",
        "Dalam dataset California Housing, fitur `ocean_proximity` merupakan fitur kategorikal yang menunjukkan kedekatan lokasi dengan laut."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.1 Encoding Categorical Attributes\n",
        "\n",
        "Pendekatan yang paling umum untuk menangani fitur kategorikal adalah **One-Hot Encoding**.\n",
        "\n",
        "One-Hot Encoding mengubah setiap kategori menjadi sebuah fitur biner (0 atau 1). Dengan cara ini, model tidak mengasumsikan adanya hubungan ordinal antar kategori."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "housing_cat = housing[[\"ocean_proximity\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_encoder = OneHotEncoder()\n",
        "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
        "housing_cat_1hot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hasil dari One-Hot Encoding berupa **sparse matrix**, yang menyimpan data secara efisien karena sebagian besar nilainya adalah nol.\n",
        "\n",
        "Setiap kolom baru merepresentasikan satu kategori unik dari fitur `ocean_proximity`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Untuk mengetahui kategori apa saja yang telah di-encode, kita dapat memeriksa atribut `categories_`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_encoder.categories_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Urutan kategori ini menentukan urutan kolom pada hasil One-Hot Encoding.\n",
        "\n",
        "Pada praktiknya, One-Hot Encoding memastikan bahwa informasi kategorikal dapat dimanfaatkan oleh algoritma Machine Learning tanpa memperkenalkan bias numerik."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Full Pipeline for Data Preparation\n",
        "\n",
        "Setelah membuat pipeline terpisah untuk fitur numerik, langkah selanjutnya adalah **menggabungkan preprocessing numerik dan kategorikal** ke dalam satu pipeline utuh.\n",
        "\n",
        "Scikit-Learn menyediakan class `ColumnTransformer` untuk menerapkan transformer yang berbeda pada subset kolom yang berbeda."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 11.1 ColumnTransformer\n",
        "\n",
        "`ColumnTransformer` memungkinkan kita:\n",
        "- menerapkan pipeline numerik pada kolom numerik,\n",
        "- menerapkan One-Hot Encoding pada kolom kategorikal,\n",
        "- menggabungkan seluruh hasil preprocessing menjadi satu matriks fitur.\n",
        "\n",
        "Pendekatan ini sangat penting untuk membangun sistem Machine Learning yang bersih dan mudah dipelihara."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "num_attribs = list(housing_num)\n",
        "cat_attribs = [\"ocean_proximity\"]\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "    (\"num\", num_pipeline, num_attribs),\n",
        "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pipeline di atas memastikan bahwa:\n",
        "- seluruh fitur numerik diproses secara konsisten,\n",
        "- fitur kategorikal diubah menjadi representasi numerik,\n",
        "- hasil akhir siap langsung digunakan oleh algoritma Machine Learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 11.2 Applying the Full Pipeline\n",
        "\n",
        "Setelah pipeline lengkap dibuat, kita dapat menerapkannya pada training set untuk menghasilkan data siap training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "housing_prepared = full_pipeline.fit_transform(housing)\n",
        "housing_prepared"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Output dari pipeline berupa matriks numerik yang telah melalui seluruh tahap preprocessing.\n",
        "\n",
        "Mulai dari titik ini, data siap digunakan untuk melatih berbagai model Machine Learning tanpa perlu preprocessing tambahan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Select and Train a Model\n",
        "\n",
        "Setelah data siap sepenuhnya, kita dapat mulai **melatih model Machine Learning**.\n",
        "\n",
        "Pendekatan yang baik adalah memulai dari model yang **sederhana** sebagai baseline, sebelum mencoba model yang lebih kompleks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 12.1 Training a Linear Regression Model\n",
        "\n",
        "Sebagai baseline, kita menggunakan **Linear Regression**. Model ini sederhana, cepat dilatih, dan memberikan gambaran awal tentang performa yang dapat dicapai."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(housing_prepared, housing_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model Linear Regression telah dilatih menggunakan data yang sudah dipreprocessing sepenuhnya melalui pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 12.2 Evaluating the Model on the Training Set\n",
        "\n",
        "Untuk mendapatkan gambaran awal performa model, kita mengevaluasi hasil prediksi pada training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "housing_predictions = lin_reg.predict(housing_prepared)\n",
        "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "lin_rmse = np.sqrt(lin_mse)\n",
        "lin_rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nilai RMSE ini memberikan indikasi awal seberapa baik Linear Regression memodelkan data.\n",
        "\n",
        "Jika error masih cukup besar, hal ini menandakan bahwa model mungkin **underfitting**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 12.3 Training a Decision Tree Regressor\n",
        "\n",
        "Untuk membandingkan performa, kita melatih model yang lebih kompleks, yaitu **Decision Tree Regressor**.\n",
        "\n",
        "Decision Tree mampu memodelkan hubungan non-linear dan interaksi antar fitur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg = DecisionTreeRegressor(random_state=42)\n",
        "tree_reg.fit(housing_prepared, housing_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 12.4 Evaluating the Decision Tree\n",
        "\n",
        "Kita kembali menghitung RMSE pada training set untuk Decision Tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "housing_predictions = tree_reg.predict(housing_prepared)\n",
        "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "tree_rmse = np.sqrt(tree_mse)\n",
        "tree_rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Jika RMSE Decision Tree sangat kecil atau bahkan nol, hal ini justru menjadi indikasi kuat bahwa model **overfitting** pada training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Better Evaluation Using Cross-Validation\n",
        "\n",
        "Evaluasi model menggunakan training set saja sering kali **menyesatkan**, terutama untuk model yang kompleks.\n",
        "\n",
        "Untuk mendapatkan estimasi performa yang lebih realistis, digunakan teknik **cross-validation**, yang membagi data training menjadi beberapa subset dan melakukan evaluasi secara bergantian."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 13.1 Cross-Validation for Decision Tree\n",
        "\n",
        "Kita akan mengevaluasi Decision Tree menggunakan **K-Fold Cross-Validation** untuk melihat performa rata-rata model pada data yang tidak digunakan saat training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(\n",
        "    tree_reg,\n",
        "    housing_prepared,\n",
        "    housing_labels,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    cv=10\n",
        ")\n",
        "\n",
        "tree_rmse_scores = np.sqrt(-scores)\n",
        "tree_rmse_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cross-validation menunjukkan bahwa performa Decision Tree pada data validasi jauh lebih buruk dibandingkan performanya pada training set.\n",
        "\n",
        "Hal ini mengonfirmasi bahwa model tersebut mengalami **overfitting**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 13.2 Cross-Validation for Linear Regression\n",
        "\n",
        "Sebagai pembanding, kita juga melakukan cross-validation pada model Linear Regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lin_scores = cross_val_score(\n",
        "    lin_reg,\n",
        "    housing_prepared,\n",
        "    housing_labels,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    cv=10\n",
        ")\n",
        "\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "lin_rmse_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Meskipun Linear Regression memiliki error yang lebih tinggi, performanya lebih stabil dan konsisten dibandingkan Decision Tree.\n",
        "\n",
        "Cross-validation membantu kita memahami trade-off antara **bias dan variance** pada berbagai model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Fine-Tune Your Model\n",
        "\n",
        "Setelah mengevaluasi beberapa model, kita beralih ke model yang lebih kuat, yaitu **Random Forest Regressor**.\n",
        "\n",
        "Random Forest merupakan model ensemble yang menggabungkan banyak Decision Tree untuk menghasilkan prediksi yang lebih stabil dan akurat."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 14.1 Training a Random Forest Regressor\n",
        "\n",
        "Random Forest bekerja dengan melatih banyak Decision Tree pada subset data dan fitur yang berbeda, kemudian menggabungkan hasil prediksinya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "forest_reg = RandomForestRegressor(random_state=42)\n",
        "forest_reg.fit(housing_prepared, housing_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 14.2 Evaluating the Random Forest Model\n",
        "\n",
        "Seperti sebelumnya, kita mengevaluasi model menggunakan cross-validation untuk mendapatkan estimasi performa yang lebih andal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "forest_scores = cross_val_score(\n",
        "    forest_reg,\n",
        "    housing_prepared,\n",
        "    housing_labels,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    cv=10\n",
        ")\n",
        "\n",
        "forest_rmse_scores = np.sqrt(-forest_scores)\n",
        "forest_rmse_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hasil cross-validation menunjukkan bahwa Random Forest memiliki error yang lebih rendah dibandingkan Linear Regression dan Decision Tree.\n",
        "\n",
        "Hal ini menunjukkan bahwa ensemble learning mampu meningkatkan performa dengan mengurangi variance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Fine-Tune Your Model (Hyperparameter Tuning)\n",
        "\n",
        "Setelah memilih model yang menjanjikan, langkah selanjutnya adalah **menyetel hyperparameter** untuk mendapatkan performa terbaik.\n",
        "\n",
        "Pada chapter ini, digunakan **GridSearchCV**, yaitu metode pencarian sistematis terhadap kombinasi hyperparameter menggunakan cross-validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 15.1 Grid Search\n",
        "\n",
        "Grid search mencoba seluruh kombinasi hyperparameter yang didefinisikan, kemudian memilih kombinasi dengan performa terbaik berdasarkan metrik evaluasi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [\n",
        "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
        "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "forest_reg = RandomForestRegressor(random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    forest_reg,\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "grid_search.fit(housing_prepared, housing_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Grid search di atas mengevaluasi berbagai kombinasi jumlah tree dan jumlah fitur yang digunakan pada setiap split.\n",
        "\n",
        "Proses ini memang memakan waktu, tetapi sering kali menghasilkan peningkatan performa yang signifikan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid_search.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Parameter terbaik yang ditemukan oleh GridSearchCV akan digunakan sebagai model final."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 16. Evaluate Your System on the Test Set\n",
        "\n",
        "Setelah seluruh proses training dan tuning selesai, langkah terakhir adalah mengevaluasi model menggunakan **test set**.\n",
        "\n",
        "Test set digunakan **hanya sekali**, pada tahap akhir, untuk mendapatkan estimasi performa model yang paling realistis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_model = grid_search.best_estimator_\n",
        "\n",
        "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
        "y_test = strat_test_set[\"median_house_value\"].copy()\n",
        "\n",
        "X_test_prepared = full_pipeline.transform(X_test)\n",
        "\n",
        "final_predictions = final_model.predict(X_test_prepared)\n",
        "\n",
        "final_mse = mean_squared_error(y_test, final_predictions)\n",
        "final_rmse = np.sqrt(final_mse)\n",
        "final_rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nilai RMSE pada test set memberikan estimasi akhir seberapa baik sistem Machine Learning bekerja pada data yang benar-benar baru.\n",
        "\n",
        "Jika performa test set jauh lebih buruk dibandingkan training atau validation set, hal ini mengindikasikan kemungkinan overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 17. Feature Importance\n",
        "\n",
        "Salah satu keunggulan Random Forest adalah kemampuannya untuk memberikan estimasi **feature importance**.\n",
        "\n",
        "Feature importance menunjukkan seberapa besar kontribusi setiap fitur terhadap prediksi model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_importances = final_model.feature_importances_\n",
        "\n",
        "feature_importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nilai feature importance ini dapat digunakan untuk:\n",
        "- memahami perilaku model,\n",
        "- mengidentifikasi fitur yang paling berpengaruh,\n",
        "- serta membantu proses feature selection di masa depan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Closing Summary (Chapter 2)\n",
        "\n",
        "Chapter 2 memberikan gambaran lengkap mengenai **alur kerja proyek Machine Learning dari awal hingga akhir**.\n",
        "\n",
        "Mulai dari memahami masalah bisnis, mengumpulkan dan mengeksplorasi data, melakukan preprocessing, membangun pipeline, melatih dan mengevaluasi model, hingga melakukan hyperparameter tuning dan evaluasi akhir.\n",
        "\n",
        "Melalui chapter ini, kita belajar bahwa keberhasilan Machine Learning tidak hanya bergantung pada algoritma, tetapi juga pada kualitas data, proses persiapan, dan evaluasi yang sistematis.\n",
        "\n",
        "Pemahaman end-to-end workflow ini menjadi fondasi yang sangat penting untuk mempelajari model dan sistem Machine Learning yang lebih kompleks pada chapter berikutnya."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
