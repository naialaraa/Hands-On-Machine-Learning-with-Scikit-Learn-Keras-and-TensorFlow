{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 15: Processing Sequences Using RNNs and CNNs\n",
    "\n",
    "Bab ini membahas **Recurrent Neural Networks (RNN)**, kelas model yang dirancang khusus untuk menangani data berurutan. Tidak seperti jaringan saraf konvensional yang menganggap semua input saling independen, RNN memiliki \"ingatan\" karena mereka mempertahankan *state* internal berdasarkan apa yang telah mereka lihat sebelumnya.\n",
    "\n",
    "## Mengapa RNN?\n",
    "RNN sangat berguna untuk:\n",
    "- **Time Series Forecasting**: Memprediksi harga saham, cuaca, atau permintaan energi.\n",
    "- **Natural Language Processing (NLP)**: Terjemahan mesin, analisis sentimen, dan chatbot.\n",
    "- **Audio Analysis**: Pengenalan suara (speech-to-text).\n",
    "\n",
    "## Daftar Isi:\n",
    "1. **Konsep Dasar RNN**: Neuron Rekuren dan Memori.\n",
    "2. **Pelatihan RNN**: Backpropagation Through Time (BPTT).\n",
    "3. **Peramalan Time Series**: Memprediksi nilai masa depan.\n",
    "4. **Menangani Urutan Panjang**: Masalah memori jangka pendek.\n",
    "5. **Sel LSTM dan GRU**: Arsitektur untuk memori jangka panjang.\n",
    "6. **CNN 1D untuk Urutan**: Alternatif RNN yang lebih cepat.\n",
    "7. **WaveNet**: Arsitektur canggih untuk audio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bagaimana RNN Bekerja?\n",
    "\n",
    "Pada setiap langkah waktu $t$, neuron rekuren menerima input $x_{(t)}$ serta outputnya sendiri dari langkah waktu sebelumnya $h_{(t-1)}$ (juga disebut *hidden state*). \n",
    "\n",
    "### Dimensi Input RNN\n",
    "Lapisan RNN di Keras mengharapkan input 3D dengan bentuk: `[batch_size, time_steps, dimensionality]`.\n",
    "- **batch_size**: Jumlah sampel per batch.\n",
    "- **time_steps**: Panjang urutan (misal: 50 hari terakhir).\n",
    "- **dimensionality**: Jumlah fitur di setiap langkah (misal: suhu, kelembaban)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# Contoh RNN Sederhana\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "print(\"Model RNN dengan 2 lapisan rekuren berhasil didefinisikan.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Peramalan Time Series (Forecasting)\n",
    "\n",
    "Sebelum menggunakan model kompleks, kita harus selalu memiliki **Baseline Metrics**:\n",
    "1. **Naive Forecasting**: Memprediksi bahwa nilai besok akan sama dengan hari ini.\n",
    "2. **Linear Regression**: Model dasar untuk melihat tren linear.\n",
    "\n",
    "### Deep RNN vs Simple RNN\n",
    "Dalam Deep RNN, kita menumpuk beberapa lapisan rekuren. Penting untuk mengatur `return_sequences=True` pada semua lapisan kecuali yang terakhir, agar lapisan berikutnya menerima urutan lengkap sebagai input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membangun Deep RNN untuk peramalan\n",
    "model_deep = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10)) # Memprediksi 10 langkah ke depan sekaligus\n",
    "])\n",
    "\n",
    "model_deep.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Masalah Short-Term Memory\n",
    "\n",
    "RNN standar (SimpleRNN) menderita masalah gradien hilang (*vanishing gradients*), sehingga mereka melupakan informasi dari awal urutan yang panjang. Solusinya adalah menggunakan sel yang lebih canggih:\n",
    "\n",
    "### LSTM (Long Short-Term Memory)\n",
    "Memperkenalkan *cell state* (jalur memori jangka panjang) dan tiga gerbang (*gates*):\n",
    "- **Forget Gate**: Memutuskan informasi apa yang dibuang.\n",
    "- **Input Gate**: Memutuskan informasi baru apa yang disimpan.\n",
    "- **Output Gate**: Memutuskan bagian memori mana yang dikeluarkan sebagai output.\n",
    "\n",
    "### GRU (Gated Recurrent Unit)\n",
    "Versi sederhana dari LSTM dengan parameter yang lebih sedikit namun performa yang seringkali setara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan LSTM\n",
    "model_lstm = keras.models.Sequential([\n",
    "    keras.layers.LSTM(50, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.LSTM(50),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "print(\"Model LSTM siap digunakan untuk urutan panjang.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. CNN 1D untuk Memproses Urutan\n",
    "\n",
    "Mengejutkannya, CNN 1D seringkali bekerja sangat baik untuk urutan dan jauh lebih cepat daripada RNN karena mereka bisa diproses secara paralel. CNN 1D meluncurkan filter di sepanjang sumbu waktu untuk mendeteksi pola lokal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan CNN 1D untuk Time Series\n",
    "model_cnn = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=20, kernel_size=4, strides=2, padding=\"valid\", input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. WaveNet\n",
    "\n",
    "WaveNet menggunakan **Dilated Convolutions** (konvolusi melebar) untuk memperluas *receptive field* secara eksponensial tanpa meningkatkan jumlah parameter secara drastis. Ini memungkinkan model untuk melihat ribuan langkah waktu ke belakang, sangat efektif untuk audio resolusi tinggi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rangkuman Praktis Bab 15\n",
    "\n",
    "1. **RNN** adalah pilihan utama untuk data berurutan, namun **SimpleRNN** terbatas pada urutan pendek.\n",
    "2. **LSTM dan GRU** wajib digunakan jika urutan Anda memiliki ketergantungan jangka panjang (long-term dependencies).\n",
    "3. **CNN 1D** adalah alternatif yang sangat cepat dan seringkali kompetitif untuk peramalan time series.\n",
    "4. Untuk peramalan, selalu bandingkan performa model Anda dengan **Naive Forecasting** agar Anda tahu apakah model benar-benar belajar pola atau hanya menebak nilai terakhir.\n",
    "5. Gunakan `TimeDistributed` jika Anda ingin memprediksi nilai untuk setiap langkah waktu dalam urutan output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
